#!/usr/bin/env python3
import numpy as np
import cv2

import rclpy
from rclpy.node import Node
from rclpy.executors import SingleThreadedExecutor

from scipy.spatial.transform import Rotation

import DR_init
from utils.realsense import ImgNode
from utils.onrobot import RG
from ultralytics import YOLOWorld
import os
from ament_index_python.packages import get_package_share_directory

from perception_interfaces.srv import PickObject


# ==========================
# ì‚¬ìš©ì ì„¤ì •
# ==========================

ROBOT_ID = "dsr01"

GRIPPER_NAME = "rg2"
TOOLCHARGER_IP = "192.168.1.1"
TOOLCHARGER_PORT = 502

MODEL_PATH = "/home/rokey/DUM-E/models/yolov8s-worldv2.pt"
YOLO_CLASSES = ["person", "cup", "scissors", "box cutter", "bottle", "laptop", "hammer"]

YOLO_CONF_TH = 0.3   # YOLO í›„ë³´ ì¸ì • ìµœì†Œ conf
PICK_CONF_TH = 0.3   # ì‹¤ì œ pick ì‹¤í–‰ ìµœì†Œ conf (ì›í•˜ë©´ ì¡°ì ˆ)

GRIPPER2CAM_PATH = "/home/rokey/DUM-E/calib/T_gripper2camera.npy"  # <- ë„¤ê°€ ì €ì¥í•œ T íŒŒì¼ ê²½ë¡œ


class VisionPickNode(Node):
    """
    LLM/ë‹¤ë¥¸ ë…¸ë“œì—ì„œ:
      /pick_object (perception/srv/PickObject) ì„œë¹„ìŠ¤ í˜¸ì¶œ
        - request.object_name = "scissors"
      ì´ ë…¸ë“œëŠ”:
        1) RealSense frame í•œ ì¥ ê°€ì ¸ì˜´
        2) YOLOWorldë¡œ object_name í´ë˜ìŠ¤ ë””í…ì…˜
        3) bbox center í”½ì…€ â†’ depth â†’ camera ì¢Œí‘œ â†’ base ì¢Œí‘œ
        4) ë°”ë¡œ pick ë™ì‘ ìˆ˜í–‰
        5) base ì¢Œí‘œ + confë¥¼ ì‘ë‹µìœ¼ë¡œ ëŒë ¤ì¤Œ
    """

    def __init__(self, img_node: ImgNode):
        super().__init__("vision_pick_node")

        # 1) RealSense ImgNode ìƒì„±
        self.img_node = img_node

        pkg_share = get_package_share_directory('perception')
        calib_path = os.path.join(pkg_share, 'config', 'T_gripper2camera.npy')
        self.gripper2cam = np.load(calib_path)

        # 2) intrinsicsê°€ ì˜¬ ë•Œê¹Œì§€ ì ê¹ ëŒ€ê¸°
        self.intrinsics = None
        while rclpy.ok() and self.intrinsics is None:
            self.get_logger().info("ğŸ“· camera intrinsics ëŒ€ê¸° ì¤‘...")
            rclpy.spin_once(self.img_node, timeout_sec=0.1)
            self.intrinsics = self.img_node.get_camera_intrinsic()

        if self.intrinsics is None:
            self.get_logger().error("âŒ ì¹´ë©”ë¼ intrinsics ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            raise RuntimeError("camera intrinsics not available")

        self.get_logger().info(f"ğŸ“· camera intrinsics ìˆ˜ì‹  ì™„ë£Œ: {self.intrinsics}")

        # 3) gripper â†” camera ë³€í™˜í–‰ë ¬ ë¡œë“œ
        self.gripper2cam = np.load(calib_path)
        self.get_logger().info(f"ğŸ”§ Loaded T_gripper2camera from {calib_path}")

        # 4) ê·¸ë¦¬í¼ / ë¡œë´‡ íŒŒë¼ë¯¸í„°
        self.gripper = RG(GRIPPER_NAME, TOOLCHARGER_IP, TOOLCHARGER_PORT)

        self.LIN_VEL = [150.0, 300.0]
        self.LIN_ACC = [150.0, 150.0]

        self.JNT_VEL = 150.0
        self.JNT_ACC = 300.0

        self.CUSTOM_HOME_JOINT = [0, 0, 90, 0, 90, 0]

        # 5) YOLOWorld ë¡œë“œ
        self.yolo_model = YOLOWorld(MODEL_PATH)
        self.yolo_model.set_classes(YOLO_CLASSES)
        self.conf_th = YOLO_CONF_TH

        # 6) ì„œë¹„ìŠ¤ ì„œë²„ ìƒì„±
        self.srv = self.create_service(
            PickObject,
            "pick_object",
            self.handle_pick_object,
        )
        self.get_logger().info("âœ… VisionPickNode ready. Service: /pick_object")

    # ============================================
    # YOLOë¡œ ì›í•˜ëŠ” í´ë˜ìŠ¤ ê°ì§€
    # ============================================
    def detect_target_object(self, color_img, target_name: str):
        """
        color_img: BGR ì´ë¯¸ì§€
        target_name: YOLO í´ë˜ìŠ¤ ì´ë¦„ (ì˜ˆ: "scissors")
        return: (cx, cy, conf) ë˜ëŠ” None
        """
        results = self.yolo_model.predict(
            source=color_img,
            conf=self.conf_th,
            imgsz=640,
            verbose=False,
        )
        res = results[0]
        boxes = res.boxes
        annotated = res.plot()  # ë””ë²„ê¹…ìš©

        if boxes is None or len(boxes) == 0:
            self.get_logger().info("[YOLO] ë°•ìŠ¤ ì—†ìŒ.")
            return None, annotated

        names = res.names
        candidates = []

        for i, box in enumerate(boxes):
            cls_id = int(box.cls[0].item())
            cls_name = names[cls_id]
            conf = float(box.conf[0].item())

            # target_name ê³¼ ë™ì¼í•œ í´ë˜ìŠ¤ë§Œ í›„ë³´
            if cls_name.lower() == target_name.lower() and conf >= self.conf_th:
                candidates.append((conf, i, cls_name))

        if not candidates:
            self.get_logger().info(f"[YOLO] '{target_name}' í´ë˜ìŠ¤ íƒì§€ ì‹¤íŒ¨.")
            return None, annotated

        # conf ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ í•˜ë‚˜ ì„ íƒ
        candidates.sort(reverse=True)
        best_conf, best_idx, best_name = candidates[0]
        best_box = boxes[best_idx]

        xyxy = best_box.xyxy[0].cpu().numpy()
        x1, y1, x2, y2 = xyxy
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
        cv2.circle(annotated, (cx, cy), 5, (0, 255, 0), -1)

        print(f"[YOLO] Target: {best_name}, conf={best_conf:.2f}, pixel=({cx},{cy})")
        return (cx, cy, best_conf), annotated

    # ============================================
    # í”½ì…€ â†’ depth
    # ============================================
    def get_depth_value(self, cx, cy, depth_frame):
        h, w = depth_frame.shape
        if 0 <= cx < w and 0 <= cy < h:
            depth_value = depth_frame[cy, cx]
            return depth_value if depth_value != 0 else None

        self.get_logger().warn(f"âš ï¸ depth out of range: ({cx}, {cy})")
        return None

    # ============================================
    # í”½ì…€ + depth â†’ ì¹´ë©”ë¼ ì¢Œí‘œ
    # ============================================
    def get_camera_pos(self, center_x, center_y, center_z, intrinsics):
        fx = intrinsics["fx"]
        fy = intrinsics["fy"]
        ppx = intrinsics["ppx"]
        ppy = intrinsics["ppy"]

        camera_x = (center_x - ppx) * center_z / fx
        camera_y = (center_y - ppy) * center_z / fy
        camera_z = center_z

        return (camera_x, camera_y, camera_z)

    # ============================================
    # ë¡œë´‡ posx â†’ 4x4 ë³€í™˜í–‰ë ¬
    # ============================================
    def get_robot_pose_matrix(self, x, y, z, rx, ry, rz):
        R = Rotation.from_euler("ZYZ", [rx, ry, rz], degrees=True).as_matrix()
        T = np.eye(4)
        T[:3, :3] = R
        T[:3, 3] = [x, y, z]
        return T

    # ============================================
    # ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ë¡œë´‡ base ì¢Œí‘œ
    # ============================================
    def transform_to_base(self, camera_coords):
        from DSR_ROBOT2 import get_current_posx  # DR_init ì„¤ì • í›„ import ê°€ëŠ¥

        coord = np.append(np.array(camera_coords), 1.0)

        # í˜„ì¬ TCP í¬ì¦ˆ (base â†’ gripper)
        tcp_pose = get_current_posx()[0]  # [x, y, z, rx, ry, rz]
        base2gripper = self.get_robot_pose_matrix(*tcp_pose)

        # base2cam = base2gripper @ gripper2cam
        base2cam = base2gripper @ self.gripper2cam
        td_coord = base2cam @ coord

        return td_coord[:3]

    # ============================================
    # ì‹¤ì œ Pick ë™ì‘
    # ============================================
    def pick_and_drop(self, x, y, z):
        from DSR_ROBOT2 import (
            movej,
            movel,
            wait,
            DR_MV_MOD_ABS,
            DR_MV_RA_DUPLICATE,
            get_current_posx,
        )
        from DR_common2 import posx

        print(f"[MOVE] Pick â†’ base({x:.3f}, {y:.3f}, {z:.3f})")

        current_pos = get_current_posx()[0]

        approach_pos = posx([
            x,
            y,
            z + 205.0,
            current_pos[3],
            current_pos[4],
            current_pos[5],
        ])

        movel(
            approach_pos,
            vel=self.LIN_VEL,
            acc=self.LIN_ACC,
            mod=DR_MV_MOD_ABS,
            ra=DR_MV_RA_DUPLICATE,
        )

        self.gripper.close_gripper()
        wait(1)

        movej(
            self.CUSTOM_HOME_JOINT,
            vel=self.JNT_VEL,
            acc=self.JNT_ACC,
            mod=DR_MV_MOD_ABS,
            ra=DR_MV_RA_DUPLICATE,
        )

        self.gripper.open_gripper()
        wait(1)

    # ============================================
    # /pick_object ì„œë¹„ìŠ¤ ì½œë°±
    # ============================================
    def handle_pick_object(self, request, response):
        target_name = request.object_name.strip()
        if not target_name:
            response.success = False
            response.message = "object_name is empty"
            response.x = response.y = response.z = 0.0
            response.confidence = 0.0
            return response

        self.get_logger().info(f"ğŸ”” pick_object ìš”ì²­: '{target_name}'")

        # 1) RealSenseì—ì„œ ìµœì‹  í”„ë ˆì„ í•œ ì¥ ê°€ì ¸ì˜¤ê¸°
        color_img = None
        depth_frame = None
        for _ in range(10):  # ìµœëŒ€ 10ë²ˆ ì •ë„ ì‹œë„
            color_img = self.img_node.get_color_frame()
            depth_frame = self.img_node.get_depth_frame()
            if color_img is not None and depth_frame is not None:
                break

        if color_img is None or depth_frame is None:
            self.get_logger().error("âŒ RealSense frame ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            response.success = False
            response.message = "No camera frame available"
            response.x = response.y = response.z = 0.0
            response.confidence = 0.0
            return response

        # 2) YOLOë¡œ íƒ€ê²Ÿ íƒì§€
        target_info, annotated = self.detect_target_object(color_img, target_name)
        # ë””ë²„ê¹…ìš©: í•„ìš”í•˜ë©´ show / save ê°€ëŠ¥
        # cv2.imshow("debug", annotated); cv2.waitKey(1)

        if target_info is None:
            response.success = False
            response.message = f"No '{target_name}' detected"
            response.x = response.y = response.z = 0.0
            response.confidence = 0.0
            return response

        cx, cy, conf = target_info

        if conf < PICK_CONF_TH:
            msg = f"conf={conf:.2f} < PICK_CONF_TH={PICK_CONF_TH:.2f}, pick skip"
            self.get_logger().warn(msg)
            response.success = False
            response.message = msg
            response.x = response.y = response.z = 0.0
            response.confidence = float(conf)
            return response

        # 3) depth â†’ camera â†’ base ì¢Œí‘œ
        z = self.get_depth_value(cx, cy, depth_frame)
        if z is None:
            msg = "Depth invalid at target pixel, skip"
            self.get_logger().warn(msg)
            response.success = False
            response.message = msg
            response.x = response.y = response.z = 0.0
            response.confidence = float(conf)
            return response

        cam_pos = self.get_camera_pos(cx, cy, z, self.intrinsics)
        base_pos = self.transform_to_base(cam_pos)
        bx, by, bz = base_pos

        self.get_logger().info(
            f"[DEBUG] target='{target_name}', pixel=({cx},{cy}), depth={z:.1f}, "
            f"cam=({cam_pos[0]:.1f},{cam_pos[1]:.1f},{cam_pos[2]:.1f}), "
            f"base=({bx:.1f},{by:.1f},{bz:.1f}), conf={conf:.2f}"
        )

        # 4) ì‹¤ì œ pick ë™ì‘ ìˆ˜í–‰
        try:
            self.pick_and_drop(bx, by, bz)
            response.success = True
            response.message = "OK"
        except Exception as e:
            self.get_logger().error(f"âŒ pick_and_drop ì¤‘ ì˜ˆì™¸: {e}")
            response.success = False
            response.message = f"pick_and_drop error: {e}"

        response.x = float(bx)
        response.y = float(by)
        response.z = float(bz)
        response.confidence = float(conf)
        return response


def main(args=None):
    rclpy.init(args=args)

    # 1) Doosan ì œì–´ìš© ë…¸ë“œ ë¨¼ì € ìƒì„±
    dsr_node = rclpy.create_node("dsr_example_demo_py", namespace=ROBOT_ID)
    DR_init.__dsr__node = dsr_node

    # 2) RealSense ImgNode ìƒì„±
    img_node = ImgNode()

    # 3) VisionPickNodeì— img_node ì£¼ì…
    vp_node = VisionPickNode(img_node)

    # 4) Executorì— ì„¸ ë…¸ë“œ ë“±ë¡ í›„ spin
    executor = SingleThreadedExecutor()
    executor.add_node(dsr_node)
    executor.add_node(img_node)
    executor.add_node(vp_node)

    try:
        executor.spin()
    finally:
        executor.shutdown()
        dsr_node.destroy_node()
        img_node.destroy_node()
        vp_node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
